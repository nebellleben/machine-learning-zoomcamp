{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1977d95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
      "0      paid_ads         NaN                         1        79450.0   \n",
      "1  social_media      retail                         1        46992.0   \n",
      "2        events  healthcare                         5        78796.0   \n",
      "3      paid_ads      retail                         2        83843.0   \n",
      "4      referral   education                         3        85012.0   \n",
      "\n",
      "  employment_status       location  interaction_count  lead_score  converted  \n",
      "0        unemployed  south_america                  4        0.94          1  \n",
      "1          employed  south_america                  1        0.80          0  \n",
      "2        unemployed      australia                  3        0.69          1  \n",
      "3               NaN      australia                  1        0.87          0  \n",
      "4     self_employed         europe                  3        0.62          1  \n"
     ]
    }
   ],
   "source": [
    "# Import Packages and Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8c1f8dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "numerical: ['lead_score', 'converted', 'number_of_courses_viewed', 'interaction_count', 'annual_income']\n",
      "lead_source                 category\n",
      "industry                    category\n",
      "number_of_courses_viewed       int64\n",
      "annual_income                float64\n",
      "employment_status           category\n",
      "location                    category\n",
      "interaction_count              int64\n",
      "lead_score                   float64\n",
      "converted                      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "# Check if the missing values are presented in the features.\n",
    "# If there are missing values:\n",
    "# For caterogiral features, replace them with 'NA'\n",
    "# For numerical features, replace with with 0.0\n",
    "\n",
    "\n",
    "\n",
    "# inspect missing values\n",
    "df.isna().sum()\n",
    "missing = ['lead_source','industry','annual_income','employment_status','location']\n",
    "df[missing].nunique()\n",
    "\n",
    "# assign N/A values\n",
    "missing_categorical = ['lead_source','industry','employment_status','location']\n",
    "missing_numerial = ['annual_income']\n",
    "\n",
    "df[missing_categorical] = df[missing_categorical].fillna('NA')\n",
    "df[missing_numerial] = df[missing_numerial].fillna(0)\n",
    "\n",
    "\n",
    "# apply the correct data type\n",
    "\n",
    "# inspect\n",
    "#print(df.dtypes)\n",
    "#print(df.nunique())\n",
    "\n",
    "categorical = ['lead_source', 'industry','employment_status','location']\n",
    "numerical = list(set(df.columns) - set(categorical) - set('converted')) # everything else except 'converted'\n",
    "\n",
    "print(f\"categorical: {categorical}\")\n",
    "print(f\"numerical: {numerical}\")\n",
    "\n",
    "df[categorical] = df[categorical].astype('category')\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e559f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "education        187\n",
       "healthcare       187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NA               134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1 What is the most frequent observation (mode) for the column industry?\n",
    "df['industry'].value_counts(ascending=False)\n",
    "\n",
    "# Answer is 'retail'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "011f5e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction_count and lead_score: 0.009888182496913084\n",
      "number_of_courses_viewed and lead_score: -0.004878998354681257\n",
      "number_of_courses_viewed and interaction_count: -0.023565222882888117\n",
      "annual_income and interaction_count: 0.02703647240481436\n"
     ]
    }
   ],
   "source": [
    "# Q2 What are the two features that have the biggest correlation?\n",
    "\n",
    "print(f'interaction_count and lead_score: {df['interaction_count'].corr(df['lead_score'])}')\n",
    "print(f'number_of_courses_viewed and lead_score: {df['number_of_courses_viewed'].corr(df['lead_score'])}')\n",
    "print(f'number_of_courses_viewed and interaction_count: {df['number_of_courses_viewed'].corr(df['interaction_count'])}')\n",
    "print(f'annual_income and interaction_count: {df['annual_income'].corr(df['interaction_count'])}')\n",
    "\n",
    "# Answer is 'annual_income and interaction_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "da674ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "\n",
    "df_alltrain, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "df_train.reset_index(drop=True)\n",
    "df_val.reset_index(drop=True)\n",
    "df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train['converted'].values\n",
    "df_train = df_train.drop(columns='converted')\n",
    "\n",
    "y_val = df_val['converted'].values\n",
    "df_val = df_val.drop(columns='converted')\n",
    "\n",
    "y_test = df_test['converted'].values\n",
    "df_test = df_test.drop(columns='converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "414d0873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mutual score of industry: 0.01\n",
      "mutual score of location: 0.0\n",
      "mutual score of lead_source: 0.03\n",
      "mutual score of employment_status: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Q3 Which of these variables has the biggest mutual information score?\n",
    "# industry\n",
    "# location\n",
    "# lead_source\n",
    "# employment_status\n",
    "\n",
    "# Make sure that the target value y is not in your dataframe.\n",
    "\n",
    "columns_to_inspect = ['industry','location','lead_source','employment_status']\n",
    "for c in columns_to_inspect:\n",
    "    print(f'mutual score of {c}: {round(mutual_info_score(y_train, df_train[c]),2)}')\n",
    "\n",
    "\n",
    "# Answer: lead_source: 0.025993724013756367\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c6077772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7295\n"
     ]
    }
   ],
   "source": [
    "# Q4 Logistic regression - What accuracy did you get?\n",
    "\n",
    "# First transform the data and apply one hot encoding\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Get accuracy\n",
    "\n",
    "accuracy = round(((y_pred >= 0.5) == y_val).mean(),4)\n",
    "print(f\"accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a626c8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop industry accuracy difference: -0.0026999999999999247\n",
      "drop employment_status accuracy difference: 0.0027000000000000357\n",
      "drop lead_score accuracy difference: -0.005499999999999949\n"
     ]
    }
   ],
   "source": [
    "# Q5 Which of following feature has the smallest difference?\n",
    "\n",
    "# Let's find the _least_ useful feature using the feature elimination technique.\n",
    "# Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "# Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "# For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "# a: 'industry'\n",
    "# b: 'employment_status'\n",
    "# c: 'lead_score'\n",
    "\n",
    "# Test importance, not used\n",
    "#params = dict(zip(dv.get_feature_names_out(), model.coef_[0].round(3)))\n",
    "#sorted(params.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "to_drop = ['industry','employment_status','lead_score']\n",
    "\n",
    "# a\n",
    "for elem in to_drop:\n",
    "    dv_a = DictVectorizer(sparse=False)\n",
    "    train_dict_a = df_train.drop(columns=elem).to_dict(orient='records')\n",
    "    X_train_a = dv_a.fit_transform(train_dict_a)\n",
    "    val_dict_a = df_val.drop(columns=elem).to_dict(orient='records')\n",
    "    X_val_a = dv.transform(val_dict_a)\n",
    "    model_a = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_a.fit(X_train_a, y_train)\n",
    "    y_pred_a = model.predict_proba(X_val_a)[:,1]\n",
    "    accuracy_a = round(((y_pred_a >= 0.5) == y_val).mean(),4)\n",
    "    print(f\"drop {elem} accuracy difference: {accuracy - accuracy_a}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c4e313b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01, accuracy: 0.726775956284153\n",
      "C = 0.1, accuracy: 0.7295081967213115\n",
      "C = 1, accuracy: 0.7295081967213115\n",
      "C = 10, accuracy: 0.7295081967213115\n",
      "C = 100, accuracy: 0.7295081967213115\n"
     ]
    }
   ],
   "source": [
    "# Q6 Which of these C leads to the best accuracy on the validation set?\n",
    "\n",
    "# Now let's train a regularized logistic regression.\n",
    "# Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "# Train models using all the features as in Q4.\n",
    "# Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "for c in C:\n",
    "    model_c = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    model_c.fit(X_train, y_train)\n",
    "    y_pred_c = model_c.predict_proba(X_val)[:,1]\n",
    "    accuracy_c = ((y_pred_c >= 0.5) == y_val).mean()\n",
    "    print(f\"C = {c}, accuracy: {accuracy_c}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
