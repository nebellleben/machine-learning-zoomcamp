{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcc8nDweXiZD"
      },
      "outputs": [],
      "source": [
        "# Apply the suggested random number generation process set by the question for reproduceability sake:\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "81fonMiq2K9N"
      },
      "outputs": [],
      "source": [
        "# Install torchsummary if not available (for Google Colab)\n",
        "try:\n",
        "    from torchsummary import summary\n",
        "except ImportError:\n",
        "    print(\"Installing torchsummary...\")\n",
        "    %pip install torchsummary -q\n",
        "    from torchsummary import summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XcNSMugTT3Zo"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "# Try to import torchsummary, but it's optional\n",
        "try:\n",
        "    from torchsummary import summary\n",
        "    HAS_TORCHSUMMARY = True\n",
        "except ImportError:\n",
        "    HAS_TORCHSUMMARY = False\n",
        "    print(\"torchsummary not available. Install with: pip install torchsummary\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGdNRirzXuBo"
      },
      "source": [
        "## Model Architecture\n",
        "\n",
        "For this homework we will use Convolutional Neural Network (CNN). We'll use PyTorch.\n",
        "\n",
        "Model structure:\n",
        "* The shape for input should be `(3, 200, 200)` (channels first format in PyTorch)\n",
        "* Next, create a convolutional layer (`nn.Conv2d`):\n",
        "    * Use 32 filters (output channels)\n",
        "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
        "    * Use `'relu'` as activation\n",
        "* Reduce the size of the feature map with max pooling (`nn.MaxPool2d`)\n",
        "    * Set the pooling size to `(2, 2)`\n",
        "* Turn the multi-dimensional result into vectors using `flatten` or `view`\n",
        "* Next, add a `nn.Linear` layer with 64 neurons and `'relu'` activation\n",
        "* Finally, create the `nn.Linear` layer with 1 neuron - this will be the output\n",
        "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
        "\n",
        "As optimizer use `torch.optim.SGD` with the following parameters:\n",
        "* `torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XBYNIwBm2K9O"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "class HairClassifierMobileNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HairClassifierMobileNet, self).__init__()\n",
        "\n",
        "        # Convolutional layer: (3, 200, 200) -> (32, 198, 198)\n",
        "        # padding=0, stride=1 (default)\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=0, stride=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Max pooling: (32, 198, 198) -> (32, 99, 99)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "        # Flatten: (32, 99, 99) -> (32 * 99 * 99,)\n",
        "        # First linear layer: 32 * 99 * 99 -> 64\n",
        "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Output layer: 64 -> 1 (binary classification)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution + ReLU\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        # Max pooling\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # First fully connected layer + ReLU\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        # Output layer + Sigmoid\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jTuX5F7VT3Zp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z6qmq3rJlq7v"
      },
      "outputs": [],
      "source": [
        "# Define HairDataset\n",
        "\n",
        "class HairDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        for label_name in self.classes:\n",
        "            label_dir = os.path.join(data_dir, label_name)\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
        "                self.labels.append(self.class_to_idx[label_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAkW_Ag3YDn7"
      },
      "source": [
        "## Question 1: Which loss function you will use?\n",
        "\n",
        "For binary classification with sigmoid activation, we use **BCELoss** (Binary Cross Entropy Loss).\n",
        "\n",
        "Answer: **nn.BCELoss()** (or **nn.BCEWithLogitsLoss()** if we didn't use sigmoid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Jd76qO7vT3Zp"
      },
      "outputs": [],
      "source": [
        "# Loss function for binary classification\n",
        "criterion = nn.BCELoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6S2xfRQYLab"
      },
      "source": [
        "## Question 2: Total number of parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3vUxjQWYDGE",
        "outputId": "9ae14bf2-9ac7-442f-eddc-359c98e12a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error using torchsummary: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n",
            "Counting manually...\n",
            "\n",
            "Total parameters: 20,073,473\n",
            "Trainable parameters: 20,073,473\n"
          ]
        }
      ],
      "source": [
        "# Question 2: Total number of parameters\n",
        "# Create model first to count parameters\n",
        "model_temp = HairClassifierMobileNet()\n",
        "\n",
        "# Method 1: Using torchsummary (if available)\n",
        "if HAS_TORCHSUMMARY:\n",
        "    try:\n",
        "        summary(model_temp, (3, 200, 200))\n",
        "    except Exception as e:\n",
        "        print(f\"Error using torchsummary: {e}\")\n",
        "        print(\"Counting manually...\")\n",
        "else:\n",
        "    print(\"torchsummary not available, counting manually...\")\n",
        "\n",
        "# Method 2: Count manually\n",
        "total_params = sum(p.numel() for p in model_temp.parameters())\n",
        "trainable_params = sum(p.numel() for p in model_temp.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cAmVj_TlbDPp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28TnsG9VT3Zp"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "We'll use the **straight/curly hair** dataset from\n",
        "`http://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip`.\n",
        "\n",
        "Once unzipped, the dataset has the following folder structure:\n",
        "- `data/train/`\n",
        "- `data/test/`\n",
        "\n",
        "Each split contains two subfolders (e.g. `curly/` and `straight/`) with images.\n",
        "We'll:\n",
        "- Download and unzip the dataset (if not already present)\n",
        "- Resize images to 200x200 as required\n",
        "- Keep it as a **binary** problem (curly vs straight).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0wyufwzT3Zp",
        "outputId": "402287db-9a73-474a-f8ef-15573646072b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "Unzipping dataset...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Download and unzip straight/curly hair dataset if not already present\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "DATA_URL = \"http://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\"\n",
        "DATA_ZIP_PATH = \"./data.zip\"\n",
        "DATA_DIR = \"./data\"\n",
        "\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(DATA_URL, DATA_ZIP_PATH)\n",
        "    print(\"Unzipping dataset...\")\n",
        "    with zipfile.ZipFile(DATA_ZIP_PATH, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    print(\"Done!\")\n",
        "else:\n",
        "    print(\"Dataset already present, skipping download.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pfOCPi0aZCn"
      },
      "source": [
        "## Generators and Training\n",
        "- We don't need to do any additional pre-processing for the images.\n",
        "- Use batch_size=20\n",
        "- Use shuffle=True for both training, but False for test.\n",
        "\n",
        "Now fit the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Cqg2rKA-T3Zp"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Path to straight/curly hair dataset (after unzipping data.zip)\n",
        "data_dir = \"./data\"\n",
        "\n",
        "# Define transforms for training (without augmentation initially)\n",
        "input_size = 200\n",
        "\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Simple transforms - just resize and normalize\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=mean,\n",
        "        std=std\n",
        "    ) # ImageNet normalization\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Load dataset splits using ImageFolder\n",
        "# Expected structure:\n",
        "# ./data/train/curly\n",
        "# ./data/train/straight\n",
        "# ./data/test/curly\n",
        "# ./data/test/straight\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "test_dir = os.path.join(data_dir, \"test\")\n",
        "\n",
        "#train_dataset = ImageFolder(train_dir, transform=transform_train)\n",
        "#test_dataset = ImageFolder(test_dir, transform=transform_test)\n",
        "\n",
        "#print(f\"Classes: {train_dataset.classes}\")\n",
        "\n",
        "# Since this dataset is already binary (curly vs straight),\n",
        "# we don't need to remap labels; ImageFolder will give 0/1 labels.\n",
        "\n",
        "# Create data loaders\n",
        "#train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "#test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "#print(f\"Training samples: {len(train_dataset)}\")\n",
        "#print(f\"Test samples: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "scAY6EOsjwkq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = HairDataset(\n",
        "    data_dir='./data/train',\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "test_dataset = HairDataset(\n",
        "    data_dir='./data/test',\n",
        "    transform=test_transforms\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xlBQiTnSoYyk"
      },
      "outputs": [],
      "source": [
        "# Model is already defined in cell 4 above\n",
        "# Create model instance for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dfqFtZo7n-4N"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create model instance\n",
        "model = HairClassifierMobileNet()\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJDVmaPKaheN",
        "outputId": "6e4dedc2-8218-4aae-cdbe-a584f9c31847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.6679, Acc: 0.6230, Val Loss: 0.6749, Val Acc: 0.6617\n",
            "Epoch 2/10, Loss: 0.5356, Acc: 0.7228, Val Loss: 0.7888, Val Acc: 0.5672\n",
            "Epoch 3/10, Loss: 0.5513, Acc: 0.6979, Val Loss: 0.6553, Val Acc: 0.6418\n",
            "Epoch 4/10, Loss: 0.4598, Acc: 0.7878, Val Loss: 0.6579, Val Acc: 0.6318\n",
            "Epoch 5/10, Loss: 0.4137, Acc: 0.8102, Val Loss: 0.7789, Val Acc: 0.6567\n",
            "Epoch 6/10, Loss: 0.4719, Acc: 0.7940, Val Loss: 0.5974, Val Acc: 0.7114\n",
            "Epoch 7/10, Loss: 0.3054, Acc: 0.8714, Val Loss: 1.2037, Val Acc: 0.5522\n",
            "Epoch 8/10, Loss: 0.5292, Acc: 0.7678, Val Loss: 1.2173, Val Acc: 0.5373\n",
            "Epoch 9/10, Loss: 0.5383, Acc: 0.7615, Val Loss: 0.8751, Val Acc: 0.6020\n",
            "Epoch 10/10, Loss: 0.4018, Acc: 0.8227, Val Loss: 0.6093, Val Acc: 0.7264\n"
          ]
        }
      ],
      "source": [
        "# Fitting model (using code from homework requirements)\n",
        "num_epochs = 10\n",
        "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        # For binary classification, apply sigmoid to outputs before thresholding for accuracy\n",
        "        # (Note: model already has sigmoid, but outputs are already sigmoided)\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    history['loss'].append(epoch_loss)\n",
        "    history['acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(test_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "    history['val_loss'].append(val_epoch_loss)\n",
        "    history['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wd0zqFWZyPpT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNT83FMvT3Zq"
      },
      "source": [
        "## Question 3: Median of training accuracy for all epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7xRDxNRT3Zq",
        "outputId": "ee7edc8c-9a00-4647-b457-7ccc8bc70c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Median training accuracy: 0.7778\n",
            "\n",
            "Training accuracies: ['0.6230', '0.7228', '0.6979', '0.7878', '0.8102', '0.7940', '0.8714', '0.7678', '0.7615', '0.8227']\n",
            "\n",
            "Answer: 0.78\n"
          ]
        }
      ],
      "source": [
        "# Question 3: Median of training accuracy\n",
        "median_train_acc = np.median(history['acc'])\n",
        "print(f\"Median training accuracy: {median_train_acc:.4f}\")\n",
        "print(f\"\\nTraining accuracies: {[f'{acc:.4f}' for acc in history['acc']]}\")\n",
        "print(f\"\\nAnswer: {median_train_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfDIszL0T3Zq"
      },
      "source": [
        "## Question 4: Standard deviation of training loss for all epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s_PfbD_T3Zq",
        "outputId": "0efdf6dc-0b68-4884-e92e-c40445966d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard deviation of training loss: 0.0950\n",
            "\n",
            "Training losses: ['0.6679', '0.5356', '0.5513', '0.4598', '0.4137', '0.4719', '0.3054', '0.5292', '0.5383', '0.4018']\n",
            "\n",
            "Answer: 0.095\n"
          ]
        }
      ],
      "source": [
        "# Question 4: Standard deviation of training loss\n",
        "std_train_loss = np.std(history['loss'])\n",
        "print(f\"Standard deviation of training loss: {std_train_loss:.4f}\")\n",
        "print(f\"\\nTraining losses: {[f'{loss:.4f}' for loss in history['loss']]}\")\n",
        "print(f\"\\nAnswer: {std_train_loss:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9TLCCA6yzv7"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "Add the augmentations to your training data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DfKydVIky7gw"
      },
      "outputs": [],
      "source": [
        "# Data augmentation for training (augmentations BEFORE ToTensor and Normalize)\n",
        "transform_train_aug = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.RandomRotation(50),\n",
        "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=mean,\n",
        "        std=std\n",
        "    )\n",
        "])\n",
        "\n",
        "# Test transforms should NOT have augmentations\n",
        "transform_test_aug = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Reload training dataset with augmentation from straight/curly hair data\n",
        "train_dataset_aug = HairDataset(\n",
        "    data_dir='./data/train',\n",
        "    transform=transform_train_aug\n",
        ")\n",
        "\n",
        "# Test dataset should use the same transforms as before (no augmentation)\n",
        "test_dataset_aug = HairDataset(\n",
        "    data_dir='./data/test',\n",
        "    transform=transform_test_aug\n",
        ")\n",
        "\n",
        "# Create new data loaders with augmented training data\n",
        "train_loader_aug = DataLoader(train_dataset_aug, batch_size=20, shuffle=True)\n",
        "test_loader_aug = DataLoader(test_dataset_aug, batch_size=20, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GGpnoU7y_E7",
        "outputId": "c8af2b03-58cd-4eeb-d1cc-d596118283ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 (with augmentation), Loss: 0.5987, Acc: 0.6854, Val Loss: 0.5535, Val Acc: 0.7313\n",
            "Epoch 2/10 (with augmentation), Loss: 0.5414, Acc: 0.7129, Val Loss: 0.6085, Val Acc: 0.6766\n",
            "Epoch 3/10 (with augmentation), Loss: 0.5053, Acc: 0.7541, Val Loss: 0.5838, Val Acc: 0.7214\n",
            "Epoch 4/10 (with augmentation), Loss: 0.5000, Acc: 0.7703, Val Loss: 0.5043, Val Acc: 0.7463\n",
            "Epoch 5/10 (with augmentation), Loss: 0.4951, Acc: 0.7690, Val Loss: 0.8445, Val Acc: 0.6020\n",
            "Epoch 6/10 (with augmentation), Loss: 0.5657, Acc: 0.7029, Val Loss: 0.5101, Val Acc: 0.7662\n",
            "Epoch 7/10 (with augmentation), Loss: 0.5681, Acc: 0.7041, Val Loss: 0.7918, Val Acc: 0.6020\n",
            "Epoch 8/10 (with augmentation), Loss: 0.4878, Acc: 0.7603, Val Loss: 0.9479, Val Acc: 0.5970\n",
            "Epoch 9/10 (with augmentation), Loss: 0.4967, Acc: 0.7566, Val Loss: 0.5562, Val Acc: 0.7214\n",
            "Epoch 10/10 (with augmentation), Loss: 0.4617, Acc: 0.7715, Val Loss: 0.5664, Val Acc: 0.7264\n"
          ]
        }
      ],
      "source": [
        "# Train for 10 more epochs with augmentation\n",
        "# Note: We're continuing to train the same model, not creating a new one\n",
        "num_epochs_aug = 10\n",
        "history_aug = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
        "\n",
        "for epoch in range(num_epochs_aug):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in tqdm(train_loader_aug, desc=f\"Epoch {epoch+1}/{num_epochs_aug} [Train+Aug]\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset_aug)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    history_aug['loss'].append(epoch_loss)\n",
        "    history_aug['acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader_aug, desc=f\"Epoch {epoch+1}/{num_epochs_aug} [Val]\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(test_dataset_aug)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "    history_aug['val_loss'].append(val_epoch_loss)\n",
        "    history_aug['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_aug} (with augmentation), \"\n",
        "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgxAL8PiT3Zr"
      },
      "source": [
        "## Question 5: Mean of test loss for all epochs (with augmentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQGnxYjCT3Zr",
        "outputId": "821eb8c5-941e-4850-a21b-381b687e0e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean test loss (with augmentation): 0.6467\n",
            "\n",
            "Test losses: ['0.5535', '0.6085', '0.5838', '0.5043', '0.8445', '0.5101', '0.7918', '0.9479', '0.5562', '0.5664']\n",
            "\n",
            "Answer: 0.647\n"
          ]
        }
      ],
      "source": [
        "# Question 5: Mean of test loss for all epochs with augmentation\n",
        "mean_test_loss_aug = np.mean(history_aug['val_loss'])\n",
        "print(f\"Mean test loss (with augmentation): {mean_test_loss_aug:.4f}\")\n",
        "print(f\"\\nTest losses: {[f'{loss:.4f}' for loss in history_aug['val_loss']]}\")\n",
        "print(f\"\\nAnswer: {mean_test_loss_aug:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFJIMvacT3Zr"
      },
      "source": [
        "## Question 6: Average of test accuracy for the last 5 epochs (epochs 6-10) with augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLODtWGsT3Zr",
        "outputId": "4c1632b3-e74f-4c37-d161-9c506e1a16ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracies for epochs 6-10: ['0.7662', '0.6020', '0.5970', '0.7214', '0.7264']\n",
            "Average test accuracy (last 5 epochs): 0.6826\n",
            "\n",
            "Answer: 0.68\n"
          ]
        }
      ],
      "source": [
        "# Question 6: Average of test accuracy for last 5 epochs (epochs 6-10, indices 5-9)\n",
        "last_5_test_acc = history_aug['val_acc'][5:10]  # Epochs 6-10 (0-indexed: 5-9)\n",
        "avg_last_5_test_acc = np.mean(last_5_test_acc)\n",
        "\n",
        "print(f\"Test accuracies for epochs 6-10: {[f'{acc:.4f}' for acc in last_5_test_acc]}\")\n",
        "print(f\"Average test accuracy (last 5 epochs): {avg_last_5_test_acc:.4f}\")\n",
        "print(f\"\\nAnswer: {avg_last_5_test_acc:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
