{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7c03930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('hello')\n",
    "# Read data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e067e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preparation\n",
    "\n",
    "numerical = ['number_of_courses_viewed','annual_income','interaction_count','lead_score','converted']\n",
    "categorical = list(set(df.columns)-set(numerical))\n",
    "\n",
    "df[numerical] = df[numerical].fillna(0)\n",
    "df[categorical] = df[categorical].fillna('NA')\n",
    "\n",
    "df[categorical] = df[categorical].astype('category')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e6252db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split function for that with random_state=1\n",
    "\n",
    "df_all_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_all_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_all_train.reset_index(inplace=True)\n",
    "df_train.reset_index(inplace=True)\n",
    "df_val.reset_index(inplace=True)\n",
    "df_test.reset_index(inplace=True)\n",
    "\n",
    "y_all_train = df_all_train['converted'].values\n",
    "y_train = df_train['converted'].values\n",
    "y_val = df_val['converted'].values\n",
    "y_test = df_test['converted'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "492dd147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_score: 0.610\n",
      "number_of_courses_viewed: 0.760\n",
      "interaction_count: 0.740\n",
      "annual_income: 0.550\n"
     ]
    }
   ],
   "source": [
    "# Question 1: ROC AUC feature importance\n",
    "\n",
    "# Which numerical variable (among the following 4) has the highest AUC?\n",
    "# lead_score\n",
    "# number_of_courses_viewed\n",
    "# interaction_count\n",
    "# annual_income\n",
    "\n",
    "target_columns = ['lead_score', 'number_of_courses_viewed', 'interaction_count', 'annual_income']\n",
    "\n",
    "for c in target_columns:\n",
    "    y_predicted = df_train[c].values\n",
    "    print('%s: %.3f' % (c, round(roc_auc_score(y_train, y_predicted),2)))\n",
    "\n",
    "\n",
    "# Answers: number_of_courses_viewed\n",
    "#lead_score: 0.610\n",
    "#number_of_courses_viewed: 0.760\n",
    "#interaction_count: 0.740\n",
    "#annual_income: 0.550\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8eec0a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.883\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Training the model\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(df_train.to_dict(orient='records'))\n",
    "X_val = dv.transform(df_val.to_dict(orient='records'))\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_val)[:,1]\n",
    "#converted_decision = (y_pred > 0.5)\n",
    "\n",
    "print(\"score: %.3f\" % (roc_auc_score(y_val, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "850b2e4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2526106128.py, line 19)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtps.append(actual_positive & predicted_positive).sum())\u001b[39m\n                                                          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "# Question 3: Precision and Recall\n",
    "\n",
    "thresholds = np.arange(0,1.01,0.01)\n",
    "\n",
    "actual_positive = (y_val==1)\n",
    "actual_negative = (y_val==0)\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "tps = []\n",
    "fps = []\n",
    "fns = []\n",
    "tns = []\n",
    "\n",
    "for th in thresholds:\n",
    "    predicted_positive = (y_pred >= th)\n",
    "    predicted_negative = (y_pred < th)\n",
    "\n",
    "    tps.append(actual_positive & predicted_positive).sum())\n",
    "    fps.append(actual_negative & predicted_positive).sum())\n",
    "    fns.append(actual_positive & predicted_negative).sum())\n",
    "    tns.append(actual_negative & predicted_negative).sum())\n",
    "\n",
    "    #precisions.append(tp / (tp + fp))\n",
    "    #recalls.append(tp / (tp + fn))\n",
    "\n",
    "pred_results = pd.Dataframe(cols=['threshold','tp','fp','fn','tn'], data=[thresholds, tps, fps, fns, tns])\n",
    "pred_results['precision'] = pred_results['tp']/(pred_results['tp']+pred_results['fp'])\n",
    "pred_results['recall'] = pred_results['tp']/(pred_results['tp']+pred_results['fn'])\n",
    "\n",
    "plt.plot(pred_results['threshold'], pred_results['precision'], label='precision')\n",
    "plt.plot(pred_results['threshold'], pred_results['recall'], label='recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01849dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: F1 Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca05d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: 5-Fold CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab3c64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6: Hyperparameter Tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
