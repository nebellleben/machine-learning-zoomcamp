{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "793fe30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx\n",
    "#!wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc1ae1",
   "metadata": {},
   "source": [
    "## Question 1: Knowing the output node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7357a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (1.23.2)\n",
      "Requirement already satisfied: coloredlogs in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (from onnxruntime) (25.9.23)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (from onnxruntime) (2.3.5)\n",
      "Requirement already satisfied: packaging in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: protobuf in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (from onnxruntime) (6.33.1)\n",
      "Requirement already satisfied: sympy in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Output name is:  output\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime\n",
    "\n",
    "import onnxruntime as ort\n",
    "\n",
    "onnxmodelpath = 'hair_classifier_v1.onnx'\n",
    "session = ort.InferenceSession(onnxmodelpath)\n",
    "\n",
    "inputs = session.get_inputs()\n",
    "outputs = session.get_outputs()\n",
    "\n",
    "input_name = inputs[0].name\n",
    "output_name = outputs[0].name\n",
    "\n",
    "\n",
    "print('Output name is: ', output_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8cbbd",
   "metadata": {},
   "source": [
    "## Question 2: Target size\n",
    "(200,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38588c4b",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now we need to turn the image into numpy array and pre-process it.\n",
    "\n",
    "After the pre-processing, what's the value in the first pixel, the R channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b2e2292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/kelvinchan/Documents/dev/mlzoomcamp/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages (12.0.0)\n"
     ]
    }
   ],
   "source": [
    "# download the images, resizing them with pillow\n",
    "\n",
    "!pip install pillow\n",
    "\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "949b6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the following pre-processing was done in the previous homework\n",
    "'''\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ) # ImageNet normalization\n",
    "])\n",
    "'''\n",
    "\n",
    "# Convert to array and preprocess\n",
    "\n",
    "def preprocess_input(img):\n",
    "    x = np.array(img, dtype='float32')\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    x = x / 255.0\n",
    "    \n",
    "    # Normalize with ImageNet mean and std\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype='float32')\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype='float32')\n",
    "    x = (x - mean) / std\n",
    "    \n",
    "    # Convert from (H, W, C) to (C, H, W) - channels first format\n",
    "    x = x.transpose(2, 0, 1)\n",
    "    \n",
    "    # Add batch dimension: (C, H, W) -> (1, C, H, W)\n",
    "    X = np.array([x])\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05fa920",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6db1c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1, 3, 200, 200)\n",
      "First value of R:  -1.073294\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Run the model with the image https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\n",
    "\n",
    "imgurl = 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'\n",
    "img = download_image(imgurl)\n",
    "img = prepare_image(img, (200, 200))\n",
    "\n",
    "X = preprocess_input(img)\n",
    "\n",
    "# X shape should be (1, 3, 200, 200) - batch, channels, height, width\n",
    "print(f\"X shape: {X.shape}\")\n",
    "\n",
    "# First value of R channel (channel 0, first pixel)\n",
    "print(\"First value of R: \", X[0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe97c9",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Now let's apply this model to this image. What's the output of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ece6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09156588464975357]\n"
     ]
    }
   ],
   "source": [
    "result = session.run([output_name], {input_name: X})\n",
    "predictions = result[0][0].tolist()\n",
    "\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
